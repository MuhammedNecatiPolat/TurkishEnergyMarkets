{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/data2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEGATIVE_IMBALANCE_PENALTY = 1.03\n",
    "POSITIVE_IMBALANCE_PENALTY = 0.97\n",
    "\n",
    "\n",
    "def calculate_negative_imbalance_price(smp, mcp):\n",
    "    return max(smp, mcp) * NEGATIVE_IMBALANCE_PENALTY\n",
    "\n",
    "\n",
    "def calculate_positive_imbalance_price(smp, mcp):\n",
    "    return min(smp, mcp) * POSITIVE_IMBALANCE_PENALTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"smpUsd\"] = df[\"smp\"] / df[\"exchangeRate\"]\n",
    "df[\"idmUsd\"] = df[\"idm\"] / df[\"exchangeRate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"positive_imbalance_price\"] = df.apply(\n",
    "    lambda row: calculate_positive_imbalance_price(row[\"smpUsd\"], row[\"mcpUsd\"]), axis=1\n",
    ")\n",
    "df[\"negative_imbalance_price\"] = df.apply(\n",
    "    lambda row: calculate_negative_imbalance_price(row[\"smpUsd\"], row[\"mcpUsd\"]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_shortselling_profit(idm, negative_imbalance_price):\n",
    "    return max(idm - negative_imbalance_price, 0)\n",
    "\n",
    "\n",
    "def calculate_long_profit(idm, positive_imbalance_price):\n",
    "    return max(positive_imbalance_price - idm, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_shortselling_loss(idm, negative_imbalance_price):\n",
    "    return max(negative_imbalance_price - idm, 0)\n",
    "\n",
    "def calculate_long_loss(idm, positive_imbalance_price):\n",
    "    return max(idm - positive_imbalance_price, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"shortselling_profit\"] = df.apply(\n",
    "    lambda row: calculate_shortselling_profit(\n",
    "        row[\"idmUsd\"], row[\"negative_imbalance_price\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "df[\"long_profit\"] = df.apply(\n",
    "    lambda row: calculate_long_profit(row[\"idmUsd\"], row[\"positive_imbalance_price\"]),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df[\"total_profit\"] = df[\"shortselling_profit\"] + df[\"long_profit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"shortselling_loss\"] = df.apply(\n",
    "    lambda row: calculate_shortselling_loss(\n",
    "        row[\"idmUsd\"], row[\"negative_imbalance_price\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df[\"long_loss\"] = df.apply(\n",
    "    lambda row: calculate_long_loss(row[\"idmUsd\"], row[\"positive_imbalance_price\"]),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df[\"total_loss\"] = df[\"shortselling_loss\"] + df[\"long_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_shortselling_profitable'] = df['shortselling_profit'] > 0\n",
    "df['is_long_profitable'] = df['long_profit'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short selling opportunities count: 372\n",
      "Long opportunities count: 2043\n",
      "Total opportunities count: 2415\n",
      "Ratio of profitable short selling opportunities: 0.042562929061784896\n",
      "Ratio of profitable long opportunities: 0.23375286041189933\n",
      "Ratio of profitable opportunities: 0.27631578947368424\n"
     ]
    }
   ],
   "source": [
    "# Calculate short selling opportunities count\n",
    "shortselling_opportunities_count = df[\"is_shortselling_profitable\"].sum()\n",
    "long_opportunities_count = df[\"is_long_profitable\"].sum()\n",
    "print(f\"Short selling opportunities count: {shortselling_opportunities_count}\")\n",
    "print(f\"Long opportunities count: {long_opportunities_count}\")\n",
    "print(f\"Total opportunities count: {shortselling_opportunities_count + long_opportunities_count}\")\n",
    "\n",
    "#print ratio of profitable short selling opportunities\n",
    "print(f\"Ratio of profitable short selling opportunities: {shortselling_opportunities_count / len(df)}\")\n",
    "print(f\"Ratio of profitable long opportunities: {long_opportunities_count /len(df)}\")\n",
    "print(f\"Ratio of profitable opportunities: {(shortselling_opportunities_count + long_opportunities_count) / len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dayOfWeek'] = pd.to_datetime(df['date']).dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['mcpUsd','netImbalanceVolume', 'idmUsd', 'hour', 'dayOfWeek']]\n",
    "y = df['is_long_profitable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns=['hour', 'dayOfWeek'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True)\n",
    "X_train_norm = (X_train - X_train.mean()) / X_train.std()\n",
    "X_test_norm = (X_test - X_train.mean()) / X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Classifiers\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(30),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    LogisticRegression(),\n",
    "    GaussianNB(),\n",
    "    GradientBoostingClassifier(),\n",
    "    LogisticRegression(),\n",
    "    MLPClassifier(),\n",
    "]\n",
    "\n",
    "\n",
    "k = 5\n",
    "preds = pd.DataFrame(index=[*range(k)])\n",
    "\n",
    "for cls in classifiers:\n",
    "    scores = cross_val_score(cls, X_train, y_train, cv=k, scoring=\"accuracy\")\n",
    "    preds[type(cls).__name__] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier          0.767879\n",
      "DecisionTreeClassifier        0.934068\n",
      "RandomForestClassifier        0.901461\n",
      "AdaBoostClassifier            0.883154\n",
      "LogisticRegression            0.878719\n",
      "GaussianNB                    0.650604\n",
      "GradientBoostingClassifier    0.939501\n",
      "MLPClassifier                 0.946365\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(preds.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "train_data = TabularDataset(X_train.join(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['medium_quality']\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./AutogluonModels/HourAndDayMediumUsd\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.1.0: Mon Oct  9 21:28:31 PDT 2023; root:xnu-10002.41.9~6/RELEASE_ARM64_T8112\n",
      "CPU Count:          8\n",
      "Memory Avail:       7.38 GB / 16.00 GB (46.2%)\n",
      "Disk Space Avail:   144.54 GB / 460.43 GB (31.4%)\n",
      "===================================================\n",
      "Train Data Rows:    6992\n",
      "Train Data Columns: 32\n",
      "Label Column:       is_long_profitable\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [False, True]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7560.35 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.35 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 29 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])  : 29 | ['hour_1', 'hour_2', 'hour_3', 'hour_4', 'hour_5', ...]\n",
      "\t\t('float', []) :  3 | ['mcpUsd', 'netImbalanceVolume', 'idmUsd']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  3 | ['mcpUsd', 'netImbalanceVolume', 'idmUsd']\n",
      "\t\t('int', ['bool']) : 29 | ['hour_1', 'hour_2', 'hour_3', 'hour_4', 'hour_5', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t32 features in original data used to generate 32 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.35 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6292, Val Rows: 700\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.4899\t = Validation score   (f1)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.5742\t = Validation score   (f1)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.193667\tvalid_set's f1: 0.821656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.8269\t = Validation score   (f1)\n",
      "\t5.97s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.9028\t = Validation score   (f1)\n",
      "\t2.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7785\t = Validation score   (f1)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7534\t = Validation score   (f1)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.8834\t = Validation score   (f1)\n",
      "\t4.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.512\t = Validation score   (f1)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.5259\t = Validation score   (f1)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.9216\t = Validation score   (f1)\n",
      "\t6.93s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.908\t = Validation score   (f1)\n",
      "\t1.66s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.8712\t = Validation score   (f1)\n",
      "\t25.78s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.9024\t = Validation score   (f1)\n",
      "\t9.17s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.833, 'LightGBM': 0.167}\n",
      "\t0.9241\t = Validation score   (f1)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 59.33s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./AutogluonModels/HourAndDayMediumUsd\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label='is_long_profitable', eval_metric='f1', log_file_path='./autogluonTabular', path='./AutogluonModels/HourAndDayMediumUsd').fit(train_data, presets='medium_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TabularPredictor.load('./AutogluonModels/HourAndDayMediumUsd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TabularDataset(X_test.join(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(test_data)\n",
    "y_pred_proba = predictor.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.9301075268817204,\n",
       " 'accuracy': 0.9702517162471396,\n",
       " 'balanced_accuracy': 0.9520888902673532,\n",
       " 'mcc': 0.9112999700331502,\n",
       " 'roc_auc': 0.9916839836238447,\n",
       " 'precision': 0.9402173913043478,\n",
       " 'recall': 0.9202127659574468}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1350,   22],\n",
       "       [  30,  346]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1367,    5],\n",
       "       [ 308,   68]])"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.9\n",
    "m_y_pred = y_pred_proba.iloc[:, 1] > threshold\n",
    "m_y_pred = m_y_pred.astype(int)\n",
    "confusion_matrix(y_test, m_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5 Precision: 0.9402173913043478\n",
      "Predicted positives ratio: 0.9202127659574468\n",
      "-----------------\n",
      "Threshold: 0.55 Precision: 0.9495798319327731\n",
      "Predicted positives ratio: 0.901595744680851\n",
      "-----------------\n",
      "Threshold: 0.6 Precision: 0.953757225433526\n",
      "Predicted positives ratio: 0.8776595744680851\n",
      "-----------------\n",
      "Threshold: 0.65 Precision: 0.9618768328445748\n",
      "Predicted positives ratio: 0.8723404255319149\n",
      "-----------------\n",
      "Threshold: 0.7 Precision: 0.9727272727272728\n",
      "Predicted positives ratio: 0.8537234042553191\n",
      "-----------------\n",
      "Threshold: 0.75 Precision: 0.9782608695652174\n",
      "Predicted positives ratio: 0.8377659574468085\n",
      "-----------------\n",
      "Threshold: 0.8 Precision: 0.9801324503311258\n",
      "Predicted positives ratio: 0.7872340425531915\n",
      "-----------------\n",
      "Threshold: 0.85 Precision: 0.9893238434163701\n",
      "Predicted positives ratio: 0.7393617021276596\n",
      "-----------------\n",
      "Threshold: 0.9 Precision: 1.0\n",
      "Predicted positives ratio: 0.699468085106383\n",
      "-----------------\n",
      "Threshold: 0.95 Precision: 1.0\n",
      "Predicted positives ratio: 0.6143617021276596\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "thresholds = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "for threshold in thresholds:\n",
    "    m_y_pred = y_pred_proba.iloc[:, 1] > threshold\n",
    "    m_y_pred = m_y_pred.astype(int)\n",
    "    print(f\"Threshold: {threshold}\", \"Precision:\", precision_score(y_test, m_y_pred, zero_division=0))\n",
    "    print(\"Predicted positives ratio:\", (m_y_pred * y_test).sum() / y_test.sum())\n",
    "    print(\"-----------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_IMBALANCE_PENALTY = 0.97\n",
    "NEGATIVE_IMBALANCE_PENALTY = 1.03\n",
    "def calculate_pnl(mcp, smp, idm, strategy):\n",
    "    positive_imbalance_price = min(mcp, smp) * POSITIVE_IMBALANCE_PENALTY\n",
    "    negative_imbalance_price = max(mcp, smp) * NEGATIVE_IMBALANCE_PENALTY\n",
    "    if strategy == 'buy':\n",
    "        return positive_imbalance_price - idm\n",
    "    elif strategy == 'sell':\n",
    "        return idm - negative_imbalance_price\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor = TabularPredictor.load(\"AutogluonModels/ag-20240515_155843\") # Time consumed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor = TabularPredictor.load(\"AutogluonModels/ag-20240515_153257\") # One later model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.7710219922380336,\n",
       " 'accuracy': 0.898741418764302,\n",
       " 'balanced_accuracy': 0.8601978785435147,\n",
       " 'mcc': 0.7065114369226215,\n",
       " 'roc_auc': 0.9473260808882822,\n",
       " 'precision': 0.7506297229219143,\n",
       " 'recall': 0.7925531914893617}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5 Precision: 0.9402173913043478\n",
      "Predicted positives ratio: 0.9202127659574468\n",
      "-----------------\n",
      "Threshold: 0.55 Precision: 0.9495798319327731\n",
      "Predicted positives ratio: 0.901595744680851\n",
      "-----------------\n",
      "Threshold: 0.6 Precision: 0.953757225433526\n",
      "Predicted positives ratio: 0.8776595744680851\n",
      "-----------------\n",
      "Threshold: 0.65 Precision: 0.9618768328445748\n",
      "Predicted positives ratio: 0.8723404255319149\n",
      "-----------------\n",
      "Threshold: 0.7 Precision: 0.9727272727272728\n",
      "Predicted positives ratio: 0.8537234042553191\n",
      "-----------------\n",
      "Threshold: 0.75 Precision: 0.9782608695652174\n",
      "Predicted positives ratio: 0.8377659574468085\n",
      "-----------------\n",
      "Threshold: 0.8 Precision: 0.9801324503311258\n",
      "Predicted positives ratio: 0.7872340425531915\n",
      "-----------------\n",
      "Threshold: 0.85 Precision: 0.9893238434163701\n",
      "Predicted positives ratio: 0.7393617021276596\n",
      "-----------------\n",
      "Threshold: 0.9 Precision: 1.0\n",
      "Predicted positives ratio: 0.699468085106383\n",
      "-----------------\n",
      "Threshold: 0.95 Precision: 1.0\n",
      "Predicted positives ratio: 0.6143617021276596\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data)\n",
    "y_pred_proba = predictor.predict_proba(test_data)\n",
    "thresholds = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "for threshold in thresholds:\n",
    "    m_y_pred = y_pred_proba.iloc[:, 1] > threshold\n",
    "    m_y_pred = m_y_pred.astype(int)\n",
    "    print(\n",
    "        f\"Threshold: {threshold}\",\n",
    "        \"Precision:\",\n",
    "        precision_score(y_test, m_y_pred, zero_division=0),\n",
    "    )\n",
    "    print(\"Predicted positives ratio:\", (m_y_pred * y_test).sum() / y_test.sum())\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5 Total PnL: 703.5624014565788 Profitable Trades ratio:  0.9402173913043478\n",
      "Threshold: 0.55 Total PnL: 712.7349977760935 Profitable Trades ratio:  0.9495798319327731\n",
      "Threshold: 0.6 Total PnL: 718.0453762828289 Profitable Trades ratio:  0.953757225433526\n",
      "Threshold: 0.65 Total PnL: 727.5013000567833 Profitable Trades ratio:  0.9618768328445748\n",
      "Threshold: 0.7 Total PnL: 739.3731339854041 Profitable Trades ratio:  0.9727272727272728\n",
      "Threshold: 0.75 Total PnL: 738.0336719387449 Profitable Trades ratio:  0.9782608695652174\n",
      "Threshold: 0.8 Total PnL: 731.4232470049888 Profitable Trades ratio:  0.9801324503311258\n",
      "Threshold: 0.85 Total PnL: 730.6017686395046 Profitable Trades ratio:  0.9893238434163701\n",
      "Threshold: 0.9 Total PnL: 727.4249866944967 Profitable Trades ratio:  1.0\n",
      "Threshold: 0.95 Total PnL: 680.2666255992062 Profitable Trades ratio:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Get X_test data from df using indexes\n",
    "X_test_df = df.loc[X_test.index]\n",
    "\n",
    "thresholds = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "y_pred = predictor.predict(test_data)\n",
    "y_pred_proba = predictor.predict_proba(test_data)\n",
    "for threshold in thresholds:\n",
    "    m_y_pred = (y_pred_proba.iloc[:, 1] > threshold).astype(int)\n",
    "    X_test_df[\"strategy\"] = m_y_pred.apply(lambda x: 'buy' if x == 1  else 'hold')\n",
    "    X_test_df[\"pnl\"] = X_test_df.apply(\n",
    "        lambda row: calculate_pnl(row[\"mcpUsd\"], row[\"smpUsd\"], row[\"idmUsd\"], row[\"strategy\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    print(f\"Threshold: {threshold}\", \"Total PnL:\", X_test_df[\"pnl\"].sum(), \"Profitable Trades ratio: \", (X_test_df[\"pnl\"] > 0).sum() / (X_test_df['strategy'] == 'buy').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.8\n",
    "m_y_pred = (y_pred_proba.iloc[:, 1] > threshold).astype(int)\n",
    "X_test_df[\"strategy\"] = m_y_pred.apply(lambda x: 'buy' if x == 1  else 'hold')\n",
    "X_test_df[\"pnl\"] = X_test_df.apply(\n",
    "    lambda row: calculate_pnl(row[\"mcpUsd\"], row[\"smpUsd\"], row[\"idmUsd\"], row[\"strategy\"]),\n",
    "    axis=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bitirme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
