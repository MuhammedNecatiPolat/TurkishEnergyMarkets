{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/data2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEGATIVE_IMBALANCE_PENALTY = 1.03\n",
    "POSITIVE_IMBALANCE_PENALTY = 0.97\n",
    "\n",
    "\n",
    "def calculate_negative_imbalance_price(smp, mcp):\n",
    "    return max(smp, mcp) * NEGATIVE_IMBALANCE_PENALTY\n",
    "\n",
    "\n",
    "def calculate_positive_imbalance_price(smp, mcp):\n",
    "    return min(smp, mcp) * POSITIVE_IMBALANCE_PENALTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"smpUsd\"] = df[\"smp\"] / df[\"exchangeRate\"]\n",
    "df[\"idmUsd\"] = df[\"idm\"] / df[\"exchangeRate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"positive_imbalance_price\"] = df.apply(\n",
    "    lambda row: calculate_positive_imbalance_price(row[\"smpUsd\"], row[\"mcpUsd\"]), axis=1\n",
    ")\n",
    "df[\"negative_imbalance_price\"] = df.apply(\n",
    "    lambda row: calculate_negative_imbalance_price(row[\"smpUsd\"], row[\"mcpUsd\"]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_shortselling_profit(idm, negative_imbalance_price):\n",
    "    return max(idm - negative_imbalance_price, 0)\n",
    "\n",
    "\n",
    "def calculate_long_profit(idm, positive_imbalance_price):\n",
    "    return max(positive_imbalance_price - idm, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_shortselling_loss(idm, negative_imbalance_price):\n",
    "    return max(negative_imbalance_price - idm, 0)\n",
    "\n",
    "def calculate_long_loss(idm, positive_imbalance_price):\n",
    "    return max(idm - positive_imbalance_price, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"shortselling_profit\"] = df.apply(\n",
    "    lambda row: calculate_shortselling_profit(\n",
    "        row[\"idmUsd\"], row[\"negative_imbalance_price\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "df[\"long_profit\"] = df.apply(\n",
    "    lambda row: calculate_long_profit(row[\"idmUsd\"], row[\"positive_imbalance_price\"]),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df[\"total_profit\"] = df[\"shortselling_profit\"] + df[\"long_profit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"shortselling_loss\"] = df.apply(\n",
    "    lambda row: calculate_shortselling_loss(\n",
    "        row[\"idmUsd\"], row[\"negative_imbalance_price\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df[\"long_loss\"] = df.apply(\n",
    "    lambda row: calculate_long_loss(row[\"idmUsd\"], row[\"positive_imbalance_price\"]),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df[\"total_loss\"] = df[\"shortselling_loss\"] + df[\"long_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_shortselling_profitable'] = df['shortselling_profit'] > 0\n",
    "df['is_long_profitable'] = df['long_profit'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short selling opportunities count: 372\n",
      "Long opportunities count: 2043\n",
      "Total opportunities count: 2415\n",
      "Ratio of profitable short selling opportunities: 0.042562929061784896\n",
      "Ratio of profitable long opportunities: 0.23375286041189933\n",
      "Ratio of profitable opportunities: 0.27631578947368424\n"
     ]
    }
   ],
   "source": [
    "# Calculate short selling opportunities count\n",
    "shortselling_opportunities_count = df[\"is_shortselling_profitable\"].sum()\n",
    "long_opportunities_count = df[\"is_long_profitable\"].sum()\n",
    "print(f\"Short selling opportunities count: {shortselling_opportunities_count}\")\n",
    "print(f\"Long opportunities count: {long_opportunities_count}\")\n",
    "print(f\"Total opportunities count: {shortselling_opportunities_count + long_opportunities_count}\")\n",
    "\n",
    "#print ratio of profitable short selling opportunities\n",
    "print(f\"Ratio of profitable short selling opportunities: {shortselling_opportunities_count / len(df)}\")\n",
    "print(f\"Ratio of profitable long opportunities: {long_opportunities_count /len(df)}\")\n",
    "print(f\"Ratio of profitable opportunities: {(shortselling_opportunities_count + long_opportunities_count) / len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dayOfWeek'] = pd.to_datetime(df['date']).dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"mcpUsd\", \"netImbalanceVolume\", \"idmUsd\", \"hour\", \"dayOfWeek\"]]\n",
    "y = df[\"is_long_profitable\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns=['hour', 'dayOfWeek'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcpUsd</th>\n",
       "      <th>netImbalanceVolume</th>\n",
       "      <th>idmUsd</th>\n",
       "      <th>hour_1</th>\n",
       "      <th>hour_2</th>\n",
       "      <th>hour_3</th>\n",
       "      <th>hour_4</th>\n",
       "      <th>hour_5</th>\n",
       "      <th>hour_6</th>\n",
       "      <th>hour_7</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "      <th>dayOfWeek_1</th>\n",
       "      <th>dayOfWeek_2</th>\n",
       "      <th>dayOfWeek_3</th>\n",
       "      <th>dayOfWeek_4</th>\n",
       "      <th>dayOfWeek_5</th>\n",
       "      <th>dayOfWeek_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.01</td>\n",
       "      <td>-1934.80</td>\n",
       "      <td>18.981593</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.31</td>\n",
       "      <td>-750.87</td>\n",
       "      <td>18.334610</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.45</td>\n",
       "      <td>-982.77</td>\n",
       "      <td>15.194393</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.31</td>\n",
       "      <td>-764.62</td>\n",
       "      <td>7.253157</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.18</td>\n",
       "      <td>-1233.29</td>\n",
       "      <td>2.208385</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mcpUsd  netImbalanceVolume     idmUsd  hour_1  hour_2  hour_3  hour_4  \\\n",
       "0   19.01            -1934.80  18.981593   False   False   False   False   \n",
       "1   18.31             -750.87  18.334610    True   False   False   False   \n",
       "2   15.45             -982.77  15.194393   False    True   False   False   \n",
       "3    7.31             -764.62   7.253157   False   False    True   False   \n",
       "4    2.18            -1233.29   2.208385   False   False   False    True   \n",
       "\n",
       "   hour_5  hour_6  hour_7  ...  hour_20  hour_21  hour_22  hour_23  \\\n",
       "0   False   False   False  ...    False    False    False    False   \n",
       "1   False   False   False  ...    False    False    False    False   \n",
       "2   False   False   False  ...    False    False    False    False   \n",
       "3   False   False   False  ...    False    False    False    False   \n",
       "4   False   False   False  ...    False    False    False    False   \n",
       "\n",
       "   dayOfWeek_1  dayOfWeek_2  dayOfWeek_3  dayOfWeek_4  dayOfWeek_5  \\\n",
       "0         True        False        False        False        False   \n",
       "1         True        False        False        False        False   \n",
       "2         True        False        False        False        False   \n",
       "3         True        False        False        False        False   \n",
       "4         True        False        False        False        False   \n",
       "\n",
       "   dayOfWeek_6  \n",
       "0        False  \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True)\n",
    "X_train_norm = (X_train - X_train.mean()) / X_train.std()\n",
    "X_test_norm = (X_test - X_train.mean()) / X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Classifiers\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(30),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    LogisticRegression(),\n",
    "    GaussianNB(),\n",
    "    GradientBoostingClassifier(),\n",
    "    LogisticRegression(),\n",
    "    MLPClassifier(),\n",
    "]\n",
    "\n",
    "\n",
    "k = 5\n",
    "preds = pd.DataFrame(index=[*range(k)])\n",
    "\n",
    "for cls in classifiers:\n",
    "    scores = cross_val_score(cls, X_train, y_train, cv=k, scoring=\"accuracy\")\n",
    "    preds[type(cls).__name__] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier          0.767879\n",
      "DecisionTreeClassifier        0.935784\n",
      "RandomForestClassifier        0.902461\n",
      "AdaBoostClassifier            0.883154\n",
      "LogisticRegression            0.878719\n",
      "GaussianNB                    0.650604\n",
      "GradientBoostingClassifier    0.939358\n",
      "MLPClassifier                 0.926774\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(preds.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "train_data = TabularDataset(X_train.join(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['medium_quality']\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./AutogluonModels/HourAndDayMediumUsdWithoutVolume\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.1.0: Mon Oct  9 21:28:31 PDT 2023; root:xnu-10002.41.9~6/RELEASE_ARM64_T8112\n",
      "CPU Count:          8\n",
      "Memory Avail:       6.75 GB / 16.00 GB (42.2%)\n",
      "Disk Space Avail:   144.28 GB / 460.43 GB (31.3%)\n",
      "===================================================\n",
      "Train Data Rows:    6992\n",
      "Train Data Columns: 32\n",
      "Label Column:       is_long_profitable\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [False, True]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6907.79 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.35 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 29 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])  : 29 | ['hour_1', 'hour_2', 'hour_3', 'hour_4', 'hour_5', ...]\n",
      "\t\t('float', []) :  3 | ['mcpUsd', 'damVolume', 'idmUsd']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  3 | ['mcpUsd', 'damVolume', 'idmUsd']\n",
      "\t\t('int', ['bool']) : 29 | ['hour_1', 'hour_2', 'hour_3', 'hour_4', 'hour_5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t32 features in original data used to generate 32 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.35 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6292, Val Rows: 700\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.1883\t = Validation score   (f1)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.2\t = Validation score   (f1)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.5993\t = Validation score   (f1)\n",
      "\t5.25s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.6542\t = Validation score   (f1)\n",
      "\t4.08s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.4776\t = Validation score   (f1)\n",
      "\t1.05s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.4891\t = Validation score   (f1)\n",
      "\t1.17s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.6398\t = Validation score   (f1)\n",
      "\t4.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.3167\t = Validation score   (f1)\n",
      "\t0.92s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.3264\t = Validation score   (f1)\n",
      "\t0.79s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.7008\t = Validation score   (f1)\n",
      "\t7.09s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.6646\t = Validation score   (f1)\n",
      "\t2.56s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.6611\t = Validation score   (f1)\n",
      "\t10.34s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.6498\t = Validation score   (f1)\n",
      "\t6.85s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.6, 'CatBoost': 0.2, 'LightGBMLarge': 0.2}\n",
      "\t0.7126\t = Validation score   (f1)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 45.62s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./AutogluonModels/HourAndDayMediumUsdWithoutVolume\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label='is_long_profitable', eval_metric='f1', log_file_path='./autogluonTabular', path='./AutogluonModels/HourAndDayMediumUsdWithoutVolume').fit(train_data, presets='medium_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "predictor = TabularPredictor.load('./AutogluonModels/HourAndDayMediumUsd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.924051</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.016407</td>\n",
       "      <td>9.409820</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.324117</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.921630</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.012131</td>\n",
       "      <td>6.934408</td>\n",
       "      <td>0.012131</td>\n",
       "      <td>6.934408</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.907975</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.004512</td>\n",
       "      <td>1.663271</td>\n",
       "      <td>0.004512</td>\n",
       "      <td>1.663271</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.902821</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>2.151295</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>2.151295</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.005849</td>\n",
       "      <td>9.167815</td>\n",
       "      <td>0.005849</td>\n",
       "      <td>9.167815</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.883436</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>4.152959</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>4.152959</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.871166</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.012976</td>\n",
       "      <td>25.782858</td>\n",
       "      <td>0.012976</td>\n",
       "      <td>25.782858</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.012524</td>\n",
       "      <td>5.973598</td>\n",
       "      <td>0.012524</td>\n",
       "      <td>5.973598</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.778523</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.039879</td>\n",
       "      <td>0.558804</td>\n",
       "      <td>0.039879</td>\n",
       "      <td>0.558804</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.753425</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.041813</td>\n",
       "      <td>0.568991</td>\n",
       "      <td>0.041813</td>\n",
       "      <td>0.568991</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.574194</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.016160</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.016160</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.525896</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.069485</td>\n",
       "      <td>0.558291</td>\n",
       "      <td>0.069485</td>\n",
       "      <td>0.558291</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.055943</td>\n",
       "      <td>0.530291</td>\n",
       "      <td>0.055943</td>\n",
       "      <td>0.530291</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.489933</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.016347</td>\n",
       "      <td>0.005276</td>\n",
       "      <td>0.016347</td>\n",
       "      <td>0.005276</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val eval_metric  pred_time_val   fit_time  \\\n",
       "0   WeightedEnsemble_L2   0.924051          f1       0.016407   9.409820   \n",
       "1       NeuralNetFastAI   0.921630          f1       0.012131   6.934408   \n",
       "2               XGBoost   0.907975          f1       0.004512   1.663271   \n",
       "3              LightGBM   0.902821          f1       0.002870   2.151295   \n",
       "4         LightGBMLarge   0.902439          f1       0.005849   9.167815   \n",
       "5              CatBoost   0.883436          f1       0.002915   4.152959   \n",
       "6        NeuralNetTorch   0.871166          f1       0.012976  25.782858   \n",
       "7            LightGBMXT   0.826923          f1       0.012524   5.973598   \n",
       "8      RandomForestGini   0.778523          f1       0.039879   0.558804   \n",
       "9      RandomForestEntr   0.753425          f1       0.041813   0.568991   \n",
       "10       KNeighborsDist   0.574194          f1       0.016160   0.005325   \n",
       "11       ExtraTreesEntr   0.525896          f1       0.069485   0.558291   \n",
       "12       ExtraTreesGini   0.512000          f1       0.055943   0.530291   \n",
       "13       KNeighborsUnif   0.489933          f1       0.016347   0.005276   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.001406           0.324117            2       True   \n",
       "1                 0.012131           6.934408            1       True   \n",
       "2                 0.004512           1.663271            1       True   \n",
       "3                 0.002870           2.151295            1       True   \n",
       "4                 0.005849           9.167815            1       True   \n",
       "5                 0.002915           4.152959            1       True   \n",
       "6                 0.012976          25.782858            1       True   \n",
       "7                 0.012524           5.973598            1       True   \n",
       "8                 0.039879           0.558804            1       True   \n",
       "9                 0.041813           0.568991            1       True   \n",
       "10                0.016160           0.005325            1       True   \n",
       "11                0.069485           0.558291            1       True   \n",
       "12                0.055943           0.530291            1       True   \n",
       "13                0.016347           0.005276            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          14  \n",
       "1          10  \n",
       "2          11  \n",
       "3           4  \n",
       "4          13  \n",
       "5           7  \n",
       "6          12  \n",
       "7           3  \n",
       "8           5  \n",
       "9           6  \n",
       "10          2  \n",
       "11          9  \n",
       "12          8  \n",
       "13          1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TabularDataset(X_test.join(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data)\n",
    "y_pred_proba = predictor.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.9301075268817204,\n",
       " 'accuracy': 0.9702517162471396,\n",
       " 'balanced_accuracy': 0.9520888902673532,\n",
       " 'mcc': 0.9112999700331502,\n",
       " 'roc_auc': 0.9916839836238447,\n",
       " 'precision': 0.9402173913043478,\n",
       " 'recall': 0.9202127659574468}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1350,   22],\n",
       "       [  30,  346]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1372,    0],\n",
       "       [ 113,  263]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.9\n",
    "m_y_pred = y_pred_proba.iloc[:, 1] > threshold\n",
    "m_y_pred = m_y_pred.astype(int)\n",
    "confusion_matrix(y_test, m_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5 Precision: 0.9402173913043478\n",
      "Predicted positives ratio: 0.9202127659574468\n",
      "-----------------\n",
      "Threshold: 0.55 Precision: 0.9495798319327731\n",
      "Predicted positives ratio: 0.901595744680851\n",
      "-----------------\n",
      "Threshold: 0.6 Precision: 0.953757225433526\n",
      "Predicted positives ratio: 0.8776595744680851\n",
      "-----------------\n",
      "Threshold: 0.65 Precision: 0.9618768328445748\n",
      "Predicted positives ratio: 0.8723404255319149\n",
      "-----------------\n",
      "Threshold: 0.7 Precision: 0.9727272727272728\n",
      "Predicted positives ratio: 0.8537234042553191\n",
      "-----------------\n",
      "Threshold: 0.75 Precision: 0.9782608695652174\n",
      "Predicted positives ratio: 0.8377659574468085\n",
      "-----------------\n",
      "Threshold: 0.8 Precision: 0.9801324503311258\n",
      "Predicted positives ratio: 0.7872340425531915\n",
      "-----------------\n",
      "Threshold: 0.85 Precision: 0.9893238434163701\n",
      "Predicted positives ratio: 0.7393617021276596\n",
      "-----------------\n",
      "Threshold: 0.9 Precision: 1.0\n",
      "Predicted positives ratio: 0.699468085106383\n",
      "-----------------\n",
      "Threshold: 0.95 Precision: 1.0\n",
      "Predicted positives ratio: 0.6143617021276596\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "thresholds = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "for threshold in thresholds:\n",
    "    m_y_pred = y_pred_proba.iloc[:, 1] > threshold\n",
    "    m_y_pred = m_y_pred.astype(int)\n",
    "    print(f\"Threshold: {threshold}\", \"Precision:\", precision_score(y_test, m_y_pred, zero_division=0))\n",
    "    print(\"Predicted positives ratio:\", (m_y_pred * y_test).sum() / y_test.sum())\n",
    "    print(\"-----------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_IMBALANCE_PENALTY = 0.97\n",
    "NEGATIVE_IMBALANCE_PENALTY = 1.03\n",
    "def calculate_pnl(mcp, smp, idm, strategy):\n",
    "    positive_imbalance_price = min(mcp, smp) * POSITIVE_IMBALANCE_PENALTY\n",
    "    negative_imbalance_price = max(mcp, smp) * NEGATIVE_IMBALANCE_PENALTY\n",
    "    if strategy == 'buy':\n",
    "        return positive_imbalance_price - idm\n",
    "    elif strategy == 'sell':\n",
    "        return idm - negative_imbalance_price\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor = TabularPredictor.load(\"AutogluonModels/ag-20240515_155843\") # Time consumed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor = TabularPredictor.load(\"AutogluonModels/ag-20240515_153257\") # One later model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.9301075268817204,\n",
       " 'accuracy': 0.9702517162471396,\n",
       " 'balanced_accuracy': 0.9520888902673532,\n",
       " 'mcc': 0.9112999700331502,\n",
       " 'roc_auc': 0.9916839836238447,\n",
       " 'precision': 0.9402173913043478,\n",
       " 'recall': 0.9202127659574468}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5 Precision: 0.9402173913043478\n",
      "Predicted positives ratio: 0.9202127659574468\n",
      "-----------------\n",
      "Threshold: 0.55 Precision: 0.9495798319327731\n",
      "Predicted positives ratio: 0.901595744680851\n",
      "-----------------\n",
      "Threshold: 0.6 Precision: 0.953757225433526\n",
      "Predicted positives ratio: 0.8776595744680851\n",
      "-----------------\n",
      "Threshold: 0.65 Precision: 0.9618768328445748\n",
      "Predicted positives ratio: 0.8723404255319149\n",
      "-----------------\n",
      "Threshold: 0.7 Precision: 0.9727272727272728\n",
      "Predicted positives ratio: 0.8537234042553191\n",
      "-----------------\n",
      "Threshold: 0.75 Precision: 0.9782608695652174\n",
      "Predicted positives ratio: 0.8377659574468085\n",
      "-----------------\n",
      "Threshold: 0.8 Precision: 0.9801324503311258\n",
      "Predicted positives ratio: 0.7872340425531915\n",
      "-----------------\n",
      "Threshold: 0.85 Precision: 0.9893238434163701\n",
      "Predicted positives ratio: 0.7393617021276596\n",
      "-----------------\n",
      "Threshold: 0.9 Precision: 1.0\n",
      "Predicted positives ratio: 0.699468085106383\n",
      "-----------------\n",
      "Threshold: 0.95 Precision: 1.0\n",
      "Predicted positives ratio: 0.6143617021276596\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "y_pred = predictor.predict(test_data)\n",
    "y_pred_proba = predictor.predict_proba(test_data)\n",
    "thresholds = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "for threshold in thresholds:\n",
    "    m_y_pred = y_pred_proba.iloc[:, 1] > threshold\n",
    "    m_y_pred = m_y_pred.astype(int)\n",
    "    print(\n",
    "        f\"Threshold: {threshold}\",\n",
    "        \"Precision:\",\n",
    "        precision_score(y_test, m_y_pred, zero_division=0),\n",
    "    )\n",
    "    print(\"Predicted positives ratio:\", (m_y_pred * y_test).sum() / y_test.sum())\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5 Total PnL: 703.5624014565788 Profitable Trades ratio:  0.9402173913043478\n",
      "Threshold: 0.55 Total PnL: 712.7349977760935 Profitable Trades ratio:  0.9495798319327731\n",
      "Threshold: 0.6 Total PnL: 718.0453762828289 Profitable Trades ratio:  0.953757225433526\n",
      "Threshold: 0.65 Total PnL: 727.5013000567833 Profitable Trades ratio:  0.9618768328445748\n",
      "Threshold: 0.7 Total PnL: 739.3731339854041 Profitable Trades ratio:  0.9727272727272728\n",
      "Threshold: 0.75 Total PnL: 738.0336719387449 Profitable Trades ratio:  0.9782608695652174\n",
      "Threshold: 0.8 Total PnL: 731.4232470049888 Profitable Trades ratio:  0.9801324503311258\n",
      "Threshold: 0.85 Total PnL: 730.6017686395046 Profitable Trades ratio:  0.9893238434163701\n",
      "Threshold: 0.9 Total PnL: 727.4249866944967 Profitable Trades ratio:  1.0\n",
      "Threshold: 0.95 Total PnL: 680.2666255992062 Profitable Trades ratio:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Get X_test data from df using indexes\n",
    "X_test_df = df.loc[X_test.index]\n",
    "\n",
    "thresholds = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "y_pred = predictor.predict(test_data)\n",
    "y_pred_proba = predictor.predict_proba(test_data)\n",
    "for threshold in thresholds:\n",
    "    m_y_pred = (y_pred_proba.iloc[:, 1] > threshold).astype(int)\n",
    "    X_test_df[\"strategy\"] = m_y_pred.apply(lambda x: 'buy' if x == 1  else 'hold')\n",
    "    X_test_df[\"pnl\"] = X_test_df.apply(\n",
    "        lambda row: calculate_pnl(row[\"mcpUsd\"], row[\"smpUsd\"], row[\"idmUsd\"], row[\"strategy\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    print(f\"Threshold: {threshold}\", \"Total PnL:\", X_test_df[\"pnl\"].sum(), \"Profitable Trades ratio: \", (X_test_df[\"pnl\"] > 0).sum() / (X_test_df['strategy'] == 'buy').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.8\n",
    "m_y_pred = (y_pred_proba.iloc[:, 1] > threshold).astype(int)\n",
    "X_test_df[\"strategy\"] = m_y_pred.apply(lambda x: 'buy' if x == 1  else 'hold')\n",
    "X_test_df[\"pnl\"] = X_test_df.apply(\n",
    "    lambda row: calculate_pnl(row[\"mcpUsd\"], row[\"smpUsd\"], row[\"idmUsd\"], row[\"strategy\"]),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openpyxl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX_test_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/data2019TestTrades.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/pandas/core/generic.py:2417\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   2404\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[1;32m   2406\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[1;32m   2407\u001b[0m     df,\n\u001b[1;32m   2408\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2415\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[1;32m   2416\u001b[0m )\n\u001b[0;32m-> 2417\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2419\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2426\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/pandas/io/formats/excel.py:943\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m    941\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 943\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bitirme/lib/python3.10/site-packages/pandas/io/excel/_openpyxl.py:57\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[0;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     46\u001b[0m     path: FilePath \u001b[38;5;241m|\u001b[39m WriteExcelBuffer \u001b[38;5;241m|\u001b[39m ExcelWriter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Use the openpyxl module as the Excel writer.\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[1;32m     59\u001b[0m     engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     62\u001b[0m         path,\n\u001b[1;32m     63\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[1;32m     67\u001b[0m     )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'"
     ]
    }
   ],
   "source": [
    "X_test_df.to_excel('./data/data2019TestTrades.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bitirme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
